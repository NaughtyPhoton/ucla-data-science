{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCLA Extension - Introduction to Data Science\n",
    "<br>COM SCI X 450.1\n",
    "<br>Author: Nathan Strong\n",
    "<br>Instructor: Ali El-Annan\n",
    "<br>Date: May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Comparing the databases Microsoft SQL Server (SQL) and Google Firestore (NoSQL)\n",
    "# Part 2: Comparing algorithms Naive Bayes (supervised) and K-Means Clustering (unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward\n",
    "This essay will compare and contrast two popular databases as well as two popular algorithms.  None of the math for the algorithms is my own (obviously), but the code to generate the following examples is all mine -- It can be downloaded from my GitHub repo here: https://github.com/NaughtyPhoton/ucla-data-science\n",
    "\n",
    "### The Study -- What is the Most Popular Programming Language as Decided by Twitter\n",
    "As a means of displaying the databases and algorithms in action, I will be doing a \"study\" of preferred programming languages as decided by Twitter.  This study is merely a vehicle to depict the technology in question. \n",
    "<br>The programming languages I would like to examine are the 5 \"Most Loved\" programming languages of 2019 as voted by the Stack Overflow Community in their Annual Developer's Survey: https://insights.stackoverflow.com/survey/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "# In order of most loved -> least loved\n",
    "SO_MOST_LOVED: Tuple[str] = ('Rust', 'Python', 'TypeScript', 'Kotlin', 'WebAssembly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Tweets with Twython\n",
    "Using the Python library Twython I can search for Tweets. Ideally, I would collect all the tweets mentioning our most loved languages within the past year, however, the Twitter API won't allow you to return that many results. Instead, I'll use the Twython.TwythonStreamer class to collect tweets while listening for a period of time.  I've already extended the TwythonStreamer class in another file to compress this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rust recieved 43 tweets during 1 minute(s).\n",
      "420 b'Exceeded connection limit for user\\r\\n'\n",
      "Python recieved 43 tweets during 1 minute(s).\n",
      "420 b'Exceeded connection limit for user\\r\\n'\n",
      "TypeScript recieved 43 tweets during 1 minute(s).\n",
      "420 b'Exceeded connection limit for user\\r\\n'\n",
      "Kotlin recieved 43 tweets during 1 minute(s).\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='stream.twitter.com', port=443): Read timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1839\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1645\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The read operation timed out\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    750\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[1;31m# there is yet no clean way to get at it from this context.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Read timed out.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='stream.twitter.com', port=443): Read timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7ad963f46b50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mtwitterStreamer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtwitterStreamer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomStreamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminutes_to_listen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMINUTES_TO_LISTEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtwitterStreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mlanguage_tweets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitterStreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\twython\\streaming\\types.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://stream.twitter.com/%s/statuses/filter.json'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m               \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\twython\\streaming\\api.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, url, method, params)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry_counter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36miter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[0mpending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_unicode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpending\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python_3_8\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mReadTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[1;31m# Standard file-like object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='stream.twitter.com', port=443): Read timed out."
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from custom_streamer import CustomStreamer\n",
    "from tweet import Tweet\n",
    "\n",
    "MINUTES_TO_LISTEN = 1\n",
    "\n",
    "language_tweets_dict: dict = {}\n",
    "for language in SO_MOST_LOVED: \n",
    "    twitterStreamer = CustomStreamer(minutes_to_listen=MINUTES_TO_LISTEN)\n",
    "    twitterStreamer.statuses.filter(track=language)\n",
    "    language_tweets_dict[language] = twitterStreamer.tweets\n",
    "    \n",
    "    print(f'{language} recieved {len(language_tweets_dict[language])} tweets during {MINUTES_TO_LISTEN} minute(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet(id_str='1266209998566092801', text='Write multithreaded web apps in Rust!\\n\\nPublished a suite of new crates that facilitates mutithreading in Rust and W… https://t.co/AmEm9PECOp', date=datetime.datetime(2020, 5, 29, 3, 29, 23, tzinfo=tzutc()), user_handle='w3reality', user_description='Elevating the Web to VR\\nedge computing | dataviz | oss | software engineering', hashtags=[])\n"
     ]
    }
   ],
   "source": [
    "print(language_tweets_dict['Rust'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Databases\n",
    "It's a good idea to store my collection of tweets in a database, as the Twitter API only allows for a limited amount of API calls. This way I can also add to my Tweet collection by running this script on different days, thus growing my sample size, and when I feel my collection is sufficient, I can stop querying for new Tweets.\n",
    "## Part 1.1 - SQL Databases\n",
    "#### What is an SQL Database?\n",
    "SQL stands for Structured Query Language; the language used to work with a relational database.  A relational database is one which finds data based on its relationship to other data.  The SQL language is (pretty much) the same between different DBMS (Database Management Systems).\n",
    "#### Microsoft SQL Server\n",
    "I chose to use the Microsoft SQL Server for this project because I have never used it before and people seem to really like it. It uses it's own flavor of SQL called \"transact-sql\" (t-sql).  It has an integrated envioronment called Microsoft SQL Manager which provides GUI tools for managing databases.  The Microsoft SQL Server can also live on a Microsoft Azure instance if the database is designed to work on the cloud.  It has a ton of other features, but notably (for data science) it has a service called SQL Server Analysis Services (SSAS) that provides tools for Machine Learning and Data Analysis (I won't be using these).\n",
    "\n",
    "First, I'll define my table, columns, and data types in the GUI app, but this can also be done directly through SQL as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/SQL_db.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SQL is a relational database, we'll need a \"foreign key, in my table which is a key that matches the \"primary key\" of another table so the data can be easily combined. In my case, I am only going to create this one table, but if I were to continue with this experiment, I would make the \"language\" column a foreign key so that I could make a seperate collection of languages and easily qeuery all the tweets for each language.\n",
    "\n",
    "<img src=\"images/SQL_table_keys.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Python with Microsoft SQL Server - pyodbc\n",
    "The easiest way to update my SQL server is with the Python library pyodbc. pyodc is an open-source Python library which provides CRUD (Create, Read, Update, Delete) methods for ODBC (Open Database Connectivity) enabled DBMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Connect to SQL Server\n",
    "connect_string = 'Driver={SQL Server Native Client RDA 11.0}; \\\n",
    "                  Server=DESKTOP-OOMFKNN; \\\n",
    "                  Database=programming_tweets; \\\n",
    "                  Trusted_Connection=yes;'\n",
    "\n",
    "with pyodbc.connect(connect_string) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Define the columns and values to be updated    \n",
    "    insert_query = \"\"\"INSERT INTO tweets (language, id_str, text, date, user_handle, user_description)\n",
    "                      VALUES (?, ?, ?, ?, ?, ?)\"\"\"\n",
    "    \n",
    "    # Loop through all the tweets\n",
    "    for language, tweets in language_tweets_dict.items():\n",
    "        for _tweet in tweets:\n",
    "            # Define the new values to insert             \n",
    "            values = (language, _tweet.id_str, _tweet.text, _tweet.date, _tweet.user_handle, _tweet.user_description)\n",
    "            \n",
    "            # Insert the new values into the database\n",
    "            cursor.execute(insert_query, values)\n",
    "    \n",
    "    # Commit the inserts     \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the database has been updated, we can read the information inside of it via a 'SELECT' query. Below, I am printing the last 5 tweets in the collection. As you can see, we'll need to do some filtering to determine which tweets are actually about programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Tall_Individual\n",
      "tweet: @RunningEagle11 @SteveRustad1 Yea he'll definitely get the rust belt,Florida,Michigan,and Pennsylvania....suuurrree… https://t.co/5p17g2U5Zt\n",
      "\n",
      "user: enderton_justin\n",
      "tweet: Renewable energy can generate billions of dollars in health benefits, study finds #RenewableEnergy #health via… https://t.co/9JoBDSHFn2\n",
      "\n",
      "user: GoatedPS\n",
      "tweet: @FussyAF @xollost @Raintastical Obviously my son miss his pops Xolo so we not gonna talk about that game w rust hurdddddd it\n",
      "\n",
      "user: AdamRust9\n",
      "tweet: RT @NCRC: At a time when underserved neighborhoods face so many challenges, we’re expanding our team to both understand and drive innovatio…\n",
      "\n",
      "user: anglehernandez\n",
      "tweet: RT @realpython: Fil: A New Python Memory Profiler for Data Scientists and Scientists #python https://t.co/FFy9ErcNS4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pyodbc.connect(connect_string) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Grab all the rows in the tweets table\n",
    "    cursor.execute('SELECT user_handle, text FROM tweets')\n",
    "    \n",
    "    [print(f'user: {x[0]}\\ntweet: {x[1]}\\n') for x in list(cursor)[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 - NoSQL Databases\n",
    "### What is a NoSQL Database?\n",
    "A NoSQL database is not as strictly defined as a SQL database.  It is really any database that is not a SQL database. The key difference is that a SQL database finds data 'relationally' by performing qeueries that group shared columns together; where-as a NoSQL database generally needs a path or an id that points directly to the file in question. Data can still be stored relationally, in that a piece of data can hold an id pointing to another piece of data, but this type of query would take two seperate commands to get to that second piece of data.\n",
    "\n",
    "Where a SQL database enforces strict typing and defining columns ahead of time, a NoSQL database is \"schema-less\" meaning that the type of data isn't enforced when it is stored. Furthermore, there is no consistent language used in a NoSQL database, such as the SQL language or CRUD operation workflow, rather, access to data is usually governed by a RESTful API (REpresentational State Transfer), a style for building systems that ensures consistent results. \n",
    "\n",
    "A schema-less interface is convenient for a project like mine, where I might discover a new field that I need while working with the data, I don't need to modify every piece of data in the database to add the new field.\n",
    "<img src=\"images/NoSQL_documents.png\" />\n",
    "\n",
    "Not having SQL means that we have to get creative at times with how we store and retrieve data. For example, say I want to store all my tweets as well as the users who tweeted them.  I probably want to have a seperate collection of users, and because we can no longer use SQL joins to collect users and tweets in one queury, it's better to make duplicate data in the two collections. This is because it is generally better to optimize reading data than writing it.\n",
    "<img src=\"images/NoSQL_duplicate_data.png\" />\n",
    "\n",
    "One of the biggest benefits of a NoSQL database is the way it is able to scale. When we have a lot of users on a SQL database, we need to scale vertically, meaning, putting our database on bigger machines. With a NoSQL database, the DBMS can spread the data across multiple servers behind the scenes, providing faster data access for users; this is known as scaling horizontally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Firestore Database\n",
    "Google's Firestore, is a NoSQL database in the cloud. Firestore is a \"document\" database, meaning that each datapoint is not a table, rather a document in a collection. Additionally, each document may contain more collections within. \n",
    "\n",
    "Perhaps the coolest part of Firestore is its realtime capabilities. I could make a website that uses JavaScript to display graphs depicting my study that \"subscribes\" to the data, and each time it is updated, my website will recieve the updates and immediately display the results without the need for another qeuery.\n",
    "\n",
    "Firestore can be extended with \"Cloud Functions\" which run on the database at specified triggers such as new documents being added, I won't be exploring this right now.\n",
    "\n",
    "Lets add our tweets to Firestore using the Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " },\n",
       " update_time {\n",
       "   seconds: 1590821955\n",
       "   nanos: 454145000\n",
       " }]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from firebase import firebase_auth\n",
    "\n",
    "# Get the db connection from firestore\n",
    "db = firebase_auth.get_db()\n",
    "\n",
    "# Get the tweets collection\n",
    "tweets_collection = db.collection('tweets')\n",
    "\n",
    "# Loop through all the tweets and add them to a batch, so we set them all at once\n",
    "batch = db.batch()\n",
    "for language, tweets in language_tweets_dict.items():\n",
    "    for _tweet in tweets:\n",
    "        document_id = _tweet.id_str\n",
    "        data = _tweet.__dict__\n",
    "        data['language'] = language\n",
    "        batch.set(tweets_collection.document(document_id), data)\n",
    "\n",
    "batch.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
