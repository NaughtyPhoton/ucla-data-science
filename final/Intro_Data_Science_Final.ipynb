{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCLA Extension - Introduction to Data Science\n",
    "<br>COM SCI X 450.1\n",
    "<br>Author: Nathan Strong\n",
    "<br>Instructor: Ali El-Annan\n",
    "<br>Date: May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Comparing the databases MongoDB (SQL) and Google Firestore (NoSQL)\n",
    "# Part 2: Comparing algorithms Naive Bayes (supervised) and K-Means Clustering (unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward\n",
    "This essay will compare and contrast two popular databses as well as two popular algorithms.  None of the math for the algorithms is my own (obviously), but the code to generate the following examples is mine -- It can be downloaded from my GitHub repo here: https://github.com/NaughtyPhoton/ucla-data-science\n",
    "\n",
    "### The Study -- What is the Most Popular Programming Language as Decided by Twitter\n",
    "As a means of displaying the databases and algorithms in action, I will be doing a \"study\" of preferred programming languages as decided by Twitter.  This study is merely a vehicle to depict the technology in question. \n",
    "<br>The programming languages I would like to examine are the 5 \"Most Loved\" programming languages of 2019 as voted by the Stack Overflow Community in their Annual Developer's Survey: https://insights.stackoverflow.com/survey/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "# In order of most loved -> least loved\n",
    "SO_MOST_LOVED: Tuple[str] = ('Rust', 'Python', 'TypeScript', 'Kotlin', 'WebAssembly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "Using the Python library Twython I can search for Tweets. Ideally, I would collect all the tweets mentioning our most loved languages within the past year, however, the Twitter API won't allow you to return that many. Insted, I'll use the Twython.TwythonStreamer class to collect tweets while listening for a period of time.  I've already extended the TwythonStreamer class in another file to compress this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from custom_streamer import CustomStreamer\n",
    "from tweet import Tweet\n",
    "\n",
    "twitterStreamer = CustomStreamer()\n",
    "# twitterStreamer.statuses.filter(track='WebAssembly')\n",
    "t_end = time.time() + 10\n",
    "while time.time() < t_end:\n",
    "    print('time loop')\n",
    "    continue\n",
    "\n",
    "tweets: List[Tweet] = twitterStreamer.disconnect()\n",
    "    \n",
    "print('done')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.1 - MongoDB (SQL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
